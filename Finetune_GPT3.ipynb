{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "244466b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d8b5e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "116d5a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: elsevier-oa-cc-by/all\n",
      "Found cached dataset elsevier-oa-cc-by (/home/user/.cache/huggingface/datasets/orieg___elsevier-oa-cc-by/all/1.0.1/90990052f835613074d87af3592fd8eaee912f17ca4d0401bcf6d2d791d45117)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"orieg/elsevier-oa-cc-by\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04d6ec58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['title', 'abstract', 'subjareas', 'keywords', 'asjc', 'body_text', 'author_highlights'],\n",
      "    num_rows: 32072\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18f89701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Autonomous systems are increasingly required in various practical applications, including unmanned aircraft, driver-less cars, healthcare robots, manufacturing robots, etc.', 'In all of these cases it is easy to imagine a situation where an autonomous system causes harm to people or property, as a result of an error in its engineering, or an unfortunate combination of circumstances.', 'Therefore, if such autonomous systems are to operate within society, we must be able to trust that their behaviour complies with the legal, social, and ethical norms of that society.', 'Determining the trustworthiness of technology in this respect is usually delegated to a regulatory body, such as the Federal Aviation Administration (for aircraft in the USA) or the Vehicle Certification Authority (for road vehicles in the UK).', 'The process is known as certification, and is used to determine the safety and reliability of safety-critical technology, including aircraft, road vehicles, nuclear reactors, pharmaceuticals, etc.', 'For non-autonomous systems, such as cars or manned aircraft, it is assumed that the operator of the system will satisfy the ethical standards of society, e.g., the pilot of a civilian aircraft does not intend to use the aircraft to commit murder, and will, if necessary, disregard legal restrictions for ethical reasons, e.g., the pilot will disregard the Rules of the Air in order to preserve human life.', 'These assumptions are an unavoidable result of the opacity of human behaviour; it is extremely difficult to pre-determine the behaviour of a human being.', 'However, autonomous systems are far more transparent, and can be engineered to meet requirements.', 'Typically these requirements are technical (“an aircraft must be able to fly at 10,000 feet”) or legal (“a car must have visible registration markings”), but in the case of autonomous systems some requirements may be ethical (e.g., “an autonomous unmanned aircraft will never choose to do something dangerous unless it has no other option”).', 'Such ethical requirements may prove essential for an autonomous system to be certified by a regulatory body, since ethical autonomy is obviously desirable.', 'Machine ethics is an emerging discipline concerned with ensuring that the behaviour of machines towards humans and other machines they interact with is ethical  [1].', 'It is an open question whether machines are, or will ever be, moral agents, i.e., in possession of an innate ability to distinguish between right or wrong.', 'However, it is necessary to enable them to adhere to our human understanding of morality, despite there exists no obvious or easy way to accomplish this  [2–5].', 'If we assume that an autonomous system can be capable of moral agency, and possibly even be a better moral agent than a person, the goal of machine ethics is to enable machines to reason ethically.', 'Notable works in this area are  [6–11].', 'Within this sub-area of machine ethics a lot of the questions traditionally studied in moral philosophy are reiterated but now from a computational perspective.', 'The focus of research lies on automated extraction and identification of ethical guidelines for conduct, as well as on automated solving of ethical ambiguities and problems.', 'These systems are often developed with the intention to be used to aid ethical decision-making by people.', 'If we assume that an autonomous system is not capable of moral agency, then the goal of machine ethics is to ensure that machines behave ethically.', 'This is done by developing methods for ethically constraining the actions of machines  [12].', 'Within this subarea of machine ethics, research focuses on identifying ethical principles that a system should not violate during its operation and developing methods for embedding consideration of these ethical principles in the decision-making process of the machine.', 'Examples of work in this area are  [13–15].', 'We are interested in representing and embedding consideration for ethical principles in the decision-making process of an autonomous system in a way that is amenable to certification.', 'The work on ethically constraining actions of autonomous machines in  [13–15] focuses on machines used in military operations and methods for stopping the autonomous machine from performing any action that is deemed unethical, but it does not consider circumstances where no ethical action is possible.', 'Our focus in this paper is on civil applications.', 'We propose a method for selecting among unethical actions, when no ethical action is possible, and for proving that a machine only behaves unethically, by choosing a minimally unethical course of action, if it has no ethical choice.', 'It appears increasingly the case, particularly in autonomous vehicles, that the autonomous control architecture is of hybrid form comprising discrete and continuous parts.', 'Traditionally such systems have been engineered using the concept of a hybrid automaton (in which continuous aspects are encapsulated within a single state of an automaton while discrete jumps are represented as transitions between these states).', 'However, as these systems have become more complex, combining discrete decision-making and continuous control in this way has created challenges for understandability and reuse of design and code.', 'Since we are particularly interested in the issue of decision-making, rather than control we have focused here on an alternative architecture, referred to as a hybrid agent architecture in which a distinguished agent is responsible for decision-making.', 'This is motivated by evidence that hybrid automata based implementations scale poorly with the complexity of decision-making when compared to agent-based control  [16,17].', 'A typical such architecture is shown in Fig. 1.', 'The discrete part is often represented by a rational agent taking the high-level decisions, providing explanations of its choices, and invoking lower-level continuous procedures  [18].', 'In this kind of hybrid autonomous system the continuous control and the higher-order decision-making components can be separated clearly.', 'The lower-level procedures appear in non-autonomous systems as well, and are familiar to certification authorities.', 'As such, we can focus analysis on the decisions the rational agent makes, given the beliefs and goals it has  [19].', 'In an autonomous system we cannot show that an agent always does the right thing, but only that its actions are taken for the right reasons.', 'Following this premise, formal verification, more precisely model checking, has been used in  [20] for providing formal evidence for the certification of autonomous unmanned aircraft.', 'Formal verification  [21] involves proving or disproving that a system is compliant with a “formally specified property”: a requirement specified in a mathematical language.', 'Formal verification is an application of Formal Methods to the challenge of system verification.', 'Model checking is a variety of formal verification in which all possible executions of a system are examined automatically based on a model of the real world.', 'Model checking takes place relative to some requirement specified in a formal language  [22].', 'In  [19,20]   formal verification is used to assess whether or not an autonomous system for an unmanned aircraft (UA) follows the specified “Rules of the Air” (ROA) that a pilot should follow  [23].', 'The stated aim in these papers is to provide evidence that the autonomous system in control of an unmanned aircraft is safe and reliable, therefore providing supporting evidence for the potential certification of such an aircraft.', 'The rationale behind using the Rules of the Air is that they provide a codified, statutory set of behaviours which human (and machine) pilots should satisfy.', 'However, there are many circumstances that are not covered by the Rules of the Air.', 'Indeed, the Rules of the Air are not intended to be exhaustive, but rather to provide a set of guidelines for pilot behaviour.', 'It is anticipated that the Rules of the Air will be implemented by a skilled and experienced pilot whose responsibility is to ensure the safe passage of the aircraft through airspace (in this case, civil airspace).', 'In those circumstances which are not covered by explicit Rules of the Air, it is the responsibility of the autonomous system in control of an unmanned aircraft to make sensible, rational, safe and ethical decisions at all times.', 'So, while the formal verification of safe and legal decision-making has been covered in previous papers, we now focus on the formal verification of ethical decision-making within autonomous systems controlling autonomous aircraft.', 'This paper is organised as follows.', 'In Section  2 we cover relevant background material on autonomous systems, machine ethics and verification.', 'In Section  3 we outline our formal theoretical framework for the implementation and verification of ethically constrained behaviour in autonomous systems and also point to some relationships of our framework to deontic logic.', 'In Section  4 we discuss our prototype implementation of this framework.', 'In Section  5 we consider three simple examples of ethical reasoning implemented in our prototype, while, in Section  6, we present our conclusions and discuss further work.', 'Webster et al.  [19]', 'discuss the analysis of an autonomous unmanned aircraft controller as a hybrid system, with an architecture such as the one given in Fig. 1.', 'The rational agent-based autonomous system in control of the unmanned aircraft was separated from lower level control systems (such as the autopilot).', 'This enables the decision space of the agent to be analysed separately from the lower level control systems.', 'Model checking (which is best applied to discrete problems) is then used to analyse the high level decision-making and methods, such as testing (or indeed theorem proving—see  [24] for an example of where program model checking of an agent is combined with a theorem proving approach based on hybrid automata), are used to verify1 the behaviour of the lower level control systems.', 'These two approaches can be used together to provide a higher level of assurance that the system would behave as expected than either can provide individually.', 'For example, it is possible to verify that an agent in control of an unmanned aircraft will always attempt an emergency landing if it runs out of fuel.', 'Then the lower-level control systems can be analysed separately to ensure that, once this decision has been taken by the agent, the auto-land systems will correctly implement the emergency landing.', 'The predominant view of rational agency is that encapsulated within the BDI model  [25].', '“BDI” stands for Beliefs, Desires, and Intentions: beliefs represent the agent’s (possibly incomplete, possibly incorrect) information about itself, other agents, and its environment; desires represent the agent’s long-term aims; while intentions represent the aims that the agent is actively pursuing.', 'There are many different agent programming languages and agent platforms based, at least in part, on the BDI approach.', 'An overview of particular languages for programming rational agents in a BDI-like way can be found in  [26].', 'Agents programmed in these languages commonly contain a set of beliefs, a set of goals (i.e., desires), and a set of plans.', 'Plans determine how an agent acts based on its beliefs and goals.', 'As a result of executing a plan, the beliefs and goals of an agent may change as the agent performs actions in its environment.', 'It is important to note that, in a typical BDI programming language, plans are supplied by a programmer not by an independent planning mechanism.', 'While the conventional hardware and software used within an autonomous machine can be certified as any complex tool, the decision-making component of an agent-based autonomous machine needs to be certified in a way that has more in common with the way persons in a position of responsibility are certified.', 'The manufacturer needs to offer evidence that the machine will make decisions for the right reasons.', 'To accomplish this, we can use formal verification  [21,24].', 'Formal verification involves proving or disproving that a system is compliant with a “formally specified property”: a requirement specified in a mathematical language.', 'Formal verification is an application of Formal Methods to the challenge of system verification.', 'Model checking is a variety of formal verification in which all possible executions of a system can be examined automatically based on a model of the real world.', 'Model checking takes place relative to some requirement specified in a formal language  [22].', 'Typically, the formal requirement, or property, is expressed within a linear temporal logic which allows us to specify what should happen at some specific moment, at some point in the future, or at all points in the future (or some more complex combination of these).', 'Computer programs for autonomous systems are typically deterministic in nature, but when placed within the real world the behaviour of deterministic systems becomes unpredictable as the real-world is non-deterministic.', 'In other words, a variety of things can happen to the system at any given time.', 'Therefore there is a range of possible things that a system can do within a given environment.', 'This can be handled within model-checking by analysing the environment to determine the finite set of input classes that effect the agents’ decision-making.', 'This approach is described in  [21,24].', 'We adapt this approach when we perform verification in our case studies in Section  5 by exploring different ways the possible ethical consequences of an agent’s choices can be represented.', 'It should be noted that an important alternative approach to the verification of hybrid systems is that of hybrid model checking   [27,28] in which the system is designed and/or implemented as a hybrid automaton and well-developed techniques are then used to model check that automaton.', 'There is also a theorem proving approach to the verification of hybrid automata  [29].', 'As discussed above, hybrid automata are not ideal when complex decision-making is involved and we consider ethical choice to be an example of complex decision-making.', 'It is certainly not ideal if we wish to verify the ethical sub-component of some system, separately to the verification of the system as a whole which, as in our case, may involve planning or learning sub-systems which operate as “black boxes” and have not been verified.', 'Model checking has been used in  [20] for providing formal evidence for the certification of autonomous unmanned aircraft.', 'Specifically, an autonomous system for an unmanned aircraft (consisting of a rational agent) was developed and formally verified using Agent Java PathFinder, a program model checker for rational agents  [30].', 'The properties verified were based on the “Rules of the Air” (ROA) and notions of Airmanship.', 'The latter refer to requirements which do not necessarily appear in the Rules of the Air (which is a statutory document), but nevertheless constitute good practice for “airmen”.', 'Clearly Airmanship can apply to an autonomous system in control of an aircraft as well as to a pilot.', 'For example, it was verified that in all cases the rational agent in control of the unmanned aircraft would request clearance before taxiing onto the manoeuvring area of an aerodrome (a specific Rule of the Air), and that in all cases the agent would check its current fuel level before take off (Airmanship), amongst other things.', 'We use this work as the basis for our case studies in Section  5.', 'Our concern in this paper is with high-level decision-making in autonomous systems that not only takes ethics into account when reasoning but which also can be proved to do so.', 'This gives us three tasks to resolve:', 'Formalise what it means for a computational system’s decision-making to be ethically constrained,', 'Demonstrate how such a formalism can be implemented,', 'Provide a logical specification against which an implemented system that claims to make ethically constrained decisions can be checked.', 'In order to show that an autonomous system has the property of making the right decisions for the right reasons, we need to first define and formally specify what the “right decisions” are, not only in the operational, but also in the moral sense of the word.', 'In this paper we mainly focus on this problem of formal specification of moral machine decisions for the purpose of verification.', 'Ethics is a sub-field of philosophy that studies moral values and moral reasoning.', 'Normative theories of ethics are concerned with designing ethical principles that constrain the behaviour of people within ethically desirable boundaries.', 'An overview of the most popular normative theories can be found in  [11].', 'Ethical principles are rules of conduct that should guide the behaviour of moral agents when making decisions.', 'Typically they are formal or abstract by design allowing for applicability in a wide range of specific situations that arise.', 'These formal principles are intended to be additionally made concrete, or substantive, constraints by applying the facts of the decision-making context.', 'For example, the formal principle of doing no harm is violated by a specific action of moving ten metres to the left when an aircraft is on the ground, therefore the aircraft should be ethically constrained from performing this action in this circumstance.', 'The same action should not be ethically constrained when the aircraft is airborne.', 'How abstract principles are transformed into substantive rules that constrain behaviour is a difficult problem, even for people.', 'An abstract ethical principle can be specified by narrowing the scope in which it should be applied, namely by specifying “what, where, why, how, by what means, by whom, or to whom an action is to be, is not to be, or may be done” (p. 295,  [31]).', 'Within machine ethics, a growing body of research has been devoted to making these transformations, e.g.,  [10,8].', 'We are interested in using ethical principles to constrain the behaviour of an agent, therefore we must answer two questions: where do we get these ethical principles and how do we transform them into precise context-dependent constraints?', 'Autonomous systems, and robots in particular, are being developed as specialised assistants and tools with a pre-designed domain of application.', 'We suggest, therefore, that we should think of autonomous systems as members of a profession and use this insight when developing ethically behaving machines.', 'For example, medical robots can be seen as members of the medical profession, while autonomous systems for unmanned aircraft can be seen as aircrew personnel.', 'If machines are seen as special members of a profession, then special ethics that apply solely to machines is not necessary.', 'We can focus not on developing ethical principles but on ensuring that an autonomous system’s high-level decision-making is subject to a code of ethics that has already been decided upon by relevant authorities and associations.', 'We make some assumptions regarding the availability of abstract ethical principles and rules.', 'We assume that each professional domain has abstract ethical principles developed, which express what is considered right and wrong within that domain.', 'For example, in the biomedical domain, the principles of respect of autonomy, nonmaleficence, beneficence and justice, as summarised on (pp. 13–14  [32]) are considered to be the core abstract ethical principles.', 'Given a set of formal principles, we still need the substantive principles to actually evaluate how ethical an intended conduct is.', 'For frequently occurring situations, the relevant institutions and governing bodies can, and do, instantiate the abstract principles into substantive rules.', 'For example, each country or biomedical institution would further instantiate the mentioned abstract ethical principles into rules that should be followed under given conditions.', 'Thus, for instance, the abstract principle of respect for autonomy is instantiated into a rule that precisely describes when a patient’s desire to refuse treatment must be observed by not forcing treatment.', 'We distinguish between anticipated contexts, for which substantive principles can be determined directly and unanticipated contexts.', 'For anticipated contexts, we can reasonably assume that substantive principles will also be defined.', 'Since machine ethical reasoning is outside of the scope of our work, for unanticipated contexts we shall assume that the agent is additionally informed, by a human attendant or by the context itself, of what constitutes a breach of an abstract principle in that context.', 'Having established where the ethical principles for an autonomous agent come from, we now elaborate on how we intend to ethically constrain the reasoning process of an agent using these principles.', 'Arkin et al.  [13,14]', 'propose an addition to the reasoning process, a so called ethical governor, effectively embedded within the agent.', 'The ethical governor evaluates each plan with respect to given ethical constraints and removes those plans that violate at least one of the constraints.', 'However, in civilian operations, stopping all actions that violate at least one ethical principle is not always a satisfactory method of ensuring ethical behaviour.', 'Assume that an agent is choosing which plan to execute and the ethical governor vetoes all available plans as unethical.', 'Should the agent just wait for the world to change?', 'What if taking no action is also unethical?', 'Situations such as these, in which each course of action leads to violating one or more ethical principles, are called “ethical dilemmas”.', 'In an ethical dilemma a person that behaves ethically would still be considered to behave ethically when she violates the lightest of the ethical principles that she could under the circumstances.', 'It is not difficult to illustrate this point with an example from medicine.', 'A core principle in medical ethics is that of not doing harm.', 'A substantive rule that ensues is to distinguish, during childbirth, between the life of an unborn child and that of its mother, i.e., both need to be preserved.', 'However, circumstances arise in which preserving both lives is not possible and the principle of doing no harm must be violated at least once by making a choice of whose life to save.', 'If a choice is not made the principle of doing no harm would be violated twice.', 'Which life to save is no longer an issue of medical ethics but an issue of private moral choice made by the mother or her next of kin.', 'Arguments can be found to justify either choosing to save the mother or the baby, and some mothers would choose differently to others.', 'However, neither choice can be considered universally moral or immoral.', 'On the other hand, doing nothing, letting both mother and child die is morally reprehensible.', 'We want an autonomous system to be capable of minimising the unethical outcomes under the circumstances where there is no ethical option available.', 'To accomplish this we need to enable the autonomous system to distinguish the available choices in terms of how badly they violate ethical principles and choose the “least unethical” one.', 'Now the question we need to resolve is: how can we constrain the unethical actions of autonomous systems but allow them to make justifiably unethical choices under certain circumstances?', 'We propose that instead of treating the ethical principles as a veto on actions, we view them instead as soft constraints.', 'With ethical principles as soft constraints an autonomous system would be allowed to violate an ethical principle, but only under the condition that there is no ethical option available and under the assurance that the unethical option chosen is the “least of all evils”.', 'To represent ethical principles and rules as soft constraints we need an ethical policy.', 'An ethical policy is an order over the rules that are applicable in the same situation, in terms of which rule it is better to violate when no ethical option is possible.', 'The principles and rules are obtained from the ethical code of conduct within a given society, but where does the policy come from?', 'Some professional codes of conduct do offer guidance as to the priority among principles in the case of conflict.', 'When such guidance is unavailable or inapplicable, people are expected to follow their own moral judgments.', 'Assuming that machines, certainly as is the case at present, are devoid of a moral judgment capability, we advance that the person who is the most influenced by the immediate consequences of the machines decision-making should be the source of the ethical policy.', 'To justify our stance we return to the example of mother and child in danger during delivery.', 'When the decision is needed about whether the life of the mother or the life of the unborn infant should be given precedence, the decision-maker makes an ethical preference and that decision maker is the person with decision-making capacity that is most influenced by the choice, i.e., the mother (the infant is not in capacity) or if the mother is not in capacity, her next of kin.', 'It is advantageous that most legal systems often clearly define both the decision-making capacity property and the next of kin relation between persons.', 'An autonomous system making ethical decisions should thus be equipped with the policy of the person or persons who would be most afflicted if a bad decision is made by the system.', 'Within our framework we cannot express how gravely an ethical principle is violated.', 'For example making a scratch on another UA counts as damaging property to the same extent as obliterating that UA is damaging property.', 'However, a plan that incorporates two actions each of which violating a principle separately is considered less ethical than a plan that has only one action that violates the same principle (assuming this second plan does not violate some other, lower ranked principle as well).', 'To construct an ethical reasoning process for machines we need to represent abstract ethical principles and specific ethical rules, paired with the context in which they apply and then invoke these at an appropriate moment in an agent’s reasoning process.', 'As noted in Section  2.1, the reasoning of a rational agent is controlled by its beliefs, its goals and its plans.', 'The plans are presumed to have been supplied by a programmer.', 'Therefore, on a trivial level, the task of ensuring that the agent acts in an ethical fashion, should lie with the programmer who should ensure that the plans are ethical.', 'Given our assumption of a pre-existing set of ethical rules, showing that such plans always preserve the rules can then be tackled using pre-existing verification approaches.', 'However, in many realistic scenarios, it is either not possible to provide an exhaustive set of plans that will cover all situations or, at least, not possible to provide such plans in full detail.', 'So, for instance, a plan may need additional complex information such as the calculation of a route or schedule that is based on the situation in which it finds itself.', 'For simplicity we will treat all such situations as the acquisition of entirely new plans.', 'There are long traditions of AI research into specialised route planners and schedulers as well as more general plan generation systems such as  [33–35], and such planners are good candidates for integration with BDI-style languages; indeed many BDI researchers are interested in such integrations.', 'In our case we were particularly interested in a route planner such as that implemented in  [36] which can generate different routes for a UA to follow.', 'The construction of an appropriate planner is not the focus of this work, which looks at how a typical BDI agent would work with the output of such a planner.', 'We do assume that such a planner can inform an agent about the relevant side effects of any plan generated—in our cases the nature of anything with which the UA might collide.', 'We do not discuss here how some system reasons to determine the side effects of such a plan, obvious candidates include simulations (e.g., as discussed in  [37]) or specialised algorithms for, for instance, reasoning about collision avoidance (indeed a verified version of such an algorithm exists  [38]).', 'See also  [3].', 'We assume therefore that there are two modes of operation for our rational agent.', 'In one mode the agent uses its pre-existing (potentially pre-verified) set of plans in situations which are within its anticipated parameters.', 'In these cases it is assumed that the programmer has taken responsibility for any ethical issues that may arise.', 'In the other mode of operation the rational agent is working outside of these parameters but has various planning resources available to it which allow it to continue to act.', 'In this situation it must use ethical reasoning to govern its actions.', 'Thus a software agent needs to apply ethical reasoning when new options become available.', 'New options are needed when:', 'no plan is available, or,', 'a plan is available, and has been attempted, but does not appear to be working.', 'We assume that the agent has access to some external planning mechanism from which it can obtain new plans.', 'The new plans supplied by the external planner can then be associated with substantive ethical rules, i.e., the sets of ethical principles which are violated by that plan (this work of association can be performed either by the agent, the planner or some other system).', 'The job of the agent, then, is to determine which of the available plans are the most ethical to follow.', 'Abstract Ethical Principle', 'Ethical Policy', 'When the context is some societal construct such as, for example, an institution, a state, or a company, it is not unusual to expect that the context informs the agent of what counts as a violation of the laws and principles by which the context is governed.', 'Within normative reasoning these are encoded as statements of the form “X counts as Y in context C”  [40,41].', 'The counts-as statements and their generation can be seen as a mechanism for implementing context instantiation, such as the one we need to transform abstract ethical principles into rules.', 'In general, an agent’s context can be identified by space, time, goals, and/or a variety of other factors.', 'However, an agent can be constructed to manage a context regardless of how abstract it is.', 'We start with the assumption that an agent’s environment is “intelligent”.', 'Instead of considering the contexts to be a passive collection of properties, we consider them to be an agent extended to facilitate structures as described in  [42].', 'The agent of  [42] is extended with two sets: Content and Context, describing the sets of agents it contains, and is contained within, respectively.', 'This agent can implement the approach of  [6] to derive the rules that should be observed by the agent it contains.', 'Ethical Rules', 'Ethical Plan Order', 'Reasoning about plans and preference-based planning has been considered before in the BDI agent literature.', 'However, to the best of our knowledge, preference-based planning has not been applied to ethical reasoning.', 'For example, in  [43] plan selection is considered in terms of agents’ desires.', 'However, the desires are not ranked, so selecting the most desirable plan is done by summing up the number of desires each plan satisfies.', 'In  [44] the agent can reason about plans by selecting the plan that can satisfy the most goals.', 'Goals are ranked and the plan selection functions much as our plan ordering above.', 'For an overview of preference-based planning in BDI agents one can consider  [45].', 'Similarly, planning with priorities is considered in the literature.', 'The difference between planning with priorities and preference-based planing is that in the first case one considers how a planner might choose which plan to develop given a ranking on the goals the agent wants to achieve, while in the second case the ranking is on the plans themselves.', 'In  [46], a planner is proposed that develops those plans which would accomplish the highest ranked goals of the agent.', 'Only after attempting to find a plan for the most preferred goals, the planner would attempt to construct a plan for reaching a less desirable goal.', 'In  [47], the issue of deadlines is considered in combination with the desirability of goals.', 'The main idea is that an agent would only be interested in pursuing a goal if it can be feasibly reached within a certain deadline.', 'Thus the plan selection and generation is influenced by the deadline by which the goal should be reached, not only by the desirability of the goal itself.', 'Preference-based planning, as well as planing with priorities and planing in general is outside of the scope of this work.', 'For now the above-described plan order is sufficient for plan selection.', 'Inevitably, in real-world implementations, the question of critical deadlines can be expected to rise.', 'Namely, the most ethical decision is not always the least unethical decision that can be made under the circumstances, but the least unethical course of action that can be feasibly accomplished under a deadline.', 'The impact of deadlines on the ethical policy, as well context-dependent policy updating in general, is an issue we intend to explore in our future work.', 'Deontic logic is the sub-field of logic and reasoning most concerned with representing and reasoning about obligations.', 'Counts-as-statements, the paradigm of which we use to represent our ethical rules, and reasoning with them are considered to belong to the field of deontological reasoning  [40].', 'Within the study of CTD imperatives, there are works considering how to extend an ordering over imperatives into an ordering over sets of imperatives, which identify states of the world and could be taken to correspond to our plans  [50], however the ordering of the sets hinges upon the inherent properties of the ranking of CTD imperatives.', 'In our prototype, ethical reasoning was integrated into a BDI agent programming language via the agents’ plan selection mechanism.', 'In accordance with our theory, we assumed that the agent’s existing plans are ethical by default and, indeed, had been formally verified as such.', 'In the scenarios we consider below we assume the verification of the formal “Rules of the Air” and notions of Airmanship as discussed in  [19] satisfied this requirement.', 'Obviously we were assisted by the existence of these rules.', 'The most significant change for Ethan  was altering the reasoning cycle so that, if no existing plan were applicable, an external planner would be queried for new plans.', 'This query involved sending the planner the current goal, and the list of ethical rules relevant to the current situation in order that the planner might note any ethical rules that could be violated by a plan’s execution.', 'We did not implement a generic planning mechanism for our investigation but relied upon hard-coded pseudo-planners customised to the scenarios studied.', 'The Ethan  reasoning cycle is shown in Fig. 2.', 'One of the reasons for selecting Gwendolen  as the basis for our implementation language, Ethan, was that it provided the potential for formally verifying ethical decision-making.', 'Gwendolen  is implemented in the AJPF  framework for model checking agent programming languages  [30].', 'AJPF  comes with a property specification language based on linear temporal logic extended with modalities for describing the beliefs of an agent.', 'In the above, Prolog conventions are used, and so capitalised names inside terms indicate free variables which are instantiated by unification (typically against the agent’s beliefs).', 'Ethan programs may also perform deductive reasoning on their atomic beliefs as described in their Prolog-style reasoning rules, e.g:', 'indicates that the program deduces that all is well if it is not the case (i.e., “∼”) that the brakes have failed (the closed world assumption is used to deduce this negation).', 'In some cases an atom in such a Prolog rule needs to specify that deduction should be applied to a specialised belief base rather than the default one.', 'In these cases the notation, predicate [belief base], is used.', 'This work on model checking ethical choices is preliminary.', 'It is undesirable to have constructs, such as beliefs and belief rules, which can potentially affect program execution, used for verification purposes alone.', 'However adapting AJPF  with a more expressive property specification language was outside the scope of this research.', 'The issue of how the approach scales remains open.', 'The work here does demonstrate that an ethical policy can be incorporated within a BDI agent in such a way that adherence to the policy can be formally verified and so we can be certain the agent will always make the most ethical choices.', 'We examined three ethical aviation scenarios for unmanned aircraft derived from discussions with domain experts: a retired Royal Air Force fast-jet navigator and a current UK private pilot licence holder.', 'We created an Ethan  program for each scenario and then verified that program.', 'It should be noted that model checking is, inherently, a technique based on an idea of exhaustive testing and, in the case where a system interacts with the real world, it is necessary to supply a computational abstraction of the world as a model.', 'In many cases it is also necessary to provide a model of the program to be verified, rather than the program itself but in the case of AJPF  this is not necessary though we do have to provide a model of the planner.', 'In each of our scenarios we have constructed our models of the planner and the real world in a slightly different way in order to demonstrate the different ways verification may be used to establish facts about the system.', 'In each of our scenarios we first tested our agent in one specific situation and then verified it in a more general model.', 'In this scenario we examine a program for a UA to line up on a runway prior to take-off which includes plans for reacting to brake failure.', 'We tested this in a simple simulation: Ahead of the aircraft is a second manned aircraft crossing the runway on a taxiway.', 'To the left and right of the runway are runway lights (which can be damaged by aircraft taxiing over them).', 'To the right of the runway is an airport staff member who has erroneously moved onto the manoeuvring area of the aerodrome.', 'Following on from ideas in  [21,24] we replaced the ethical planner we used in the case study with a model that contained a random component.', 'This model assumed that plans could potentially be available that violated any combination of the ethical concerns in the policy.', 'An example of such a plan is given in Code fragment 5.3.', 'This “random” planner then selected a random subset of these plans and returned them to the agent.', 'This meant we were no longer “testing” the agent in the simple simulation where we assumed the existence of aircraft and airport infrastructure in specific places in relation to the agent, but instead in a random environment where aircraft or infrastructure could potentially appear on any of the alternative routes.', 'When executed in combination with a model-checking algorithm the random choice caused the search space to branch and so the model-checking examined every possible set of plans that might be returned by the ethical planner.', 'This allowed us to show that the most ethical plan was always chosen no matter what set of plans were available.', 'In effect this verification demonstrates that, on this example at least, the underlying implementation of ethical choice was correct.', 'It took our system over 21 h to verify each of 65,534 combinations of the 15 possible plans giving a total verification time of nearly four days for the four properties.', 'This example is based on a program for avoiding other aircraft in accordance with the Rules of the Air.', 'This program takes into account the possibility that some other aircraft, possibly a malicious intruder, but potentially also some ill-trained new pilot, appears on a collision course with the UA and fails to take the anticipated evasive actions.', 'An abridged version of the code for this example is shown in Code Fragment 5.5.', 'Here, *route(eAvoid, turnRight) causes the intention to suspend execution until the agent believes it has a route for turning right.', 'The action wait suspends the intention for a set time to allow the effects of actions to manifest.', 'Lines 14–15 are triggered when information arrives from the DAS that there is an intruder.', 'As a result the flight phase changes from cruise to eAvoid and a new goal is set up to avoid a collision.', 'The existing, ROA-compliant, plan for this goal is to get a route for turning right, enact that route and wait a short period to see if a collision will now be avoided.', 'If the plan succeeds the belief that there is an intruder will vanish, the flight phase can be changed back to cruise, and the goal will be achieved since the agent now believes a collision has been avoided (see the belief rule in line 8).', 'When the existing plan fails, the plans in Fragment 5.4 are added to the agent’s plan library.', 'The first of these (turn_left) is attempted first.', 'This also fails and the agent then attempts the third plan (return_to_base), which succeeds.', 'For this example we chose to leave the planner unchanged, so the ethical outcomes of turning left, emergency landing and returning to base remain fixed, but instead had random behaviour from the oncoming Erratic Intruder.', 'Essentially we are examining the success and/or failure of all the possible plans in the scenario.', 'So rather than verifying every possible ethical annotation on a plan, we verified that the system continued to reason ethically as the external situation changed.', 'Obviously it would have been possible to combine random behaviour on the part of the intruder, with random annotations on the available plans to increase the scope of the verification result.', 'The verification of each property took between 21 and 25 s and explored 54 model states on 3.06 GHz iMac with 4 GB of memory.', 'Our final program was one for handling “fuel low” alerts from the Fuel subsystem causing the UA to attempt to land.', 'In our test environment, if the agent cannot locate a safe landing site the ethical planner is invoked and returns three options (shown with ethical concerns violated and their ranks):', 'Land in field with overhead power lines.', 'Violates: do not cause damage to critical infrastructure (4); do not collide with objects on ground (3); 500 feet low-flying ROA (2); do not damage own aircraft (1).', 'Land in field with people.', 'Violates: do not collide with people (5); 500 feet low-flying ROA (2).', 'Land on an empty public road.', 'Violates: do not cause damage to critical infrastructure (4); 500 feet low-flying ROA (2).', 'The agent then chooses the most ethical–the third plan–although both the first and third plans violate an ethical concern of severity 4, the first plan also violates a concern of severity 3 while the third plan does not.', 'The verification of each property took between 7 and 10 s and explored 64 model states on 3.06 GHz iMac with 4 GB of memory.', 'Our example programs are really only fragments of some larger program for control of a UA and in each case we have chosen to verify only a single property, demonstrating different ways models of the behaviour of the real world and the planning system can be created in order to allow verification.', 'Obviously a full formal verification of an ethical UA would want to examine the full program, verify against several properties and use the model most appropriate to the full system—i.e., a model based on the construction of the planner, ethical annotation system, and a detailed understanding of the operational environment (all aspects outside the scope of this paper).', 'Our aim has not been to present a verified ethical UA but to demonstrate how our system for reasoning about ethical concerns, can be combined with an existing system in order to verify properties relating to the ethical operation of an autonomous system.', 'Before an autonomous system is allowed to operate in a shared environment with people or other autonomous systems, sufficient assurances have to be provided that it will always behave within acceptable legal, ethical, and social boundaries.', 'We propose a method for, and have implemented a working prototype of, an ethical extension to a rational agent governing an unmanned aircraft (UA).', 'The agent can be provided with a particular ethical policy it uses to distinguish among possible plans and to select the most ethical plan for execution.', 'We are able to prove formally that the prototype only performs an unethical action if the rest of the actions available to it are even less ethical.', 'Obviously there are limitations to what formal verification can tell us, particularly since many simplifications are involved.', 'In our case we assume that the plans the agent receives have been correctly annotated with ethical consequences.', 'Integration with assertion-based simulation and hardware-based testing can help in defining the limitations of formal verification and in developing a truly reliable system.', 'A methodology for an integrated approach is currently being developed  [52] and we would be interested in developing a fuller set of examples for our system and investigating them in such a framework.', 'The ethically enhanced agent is autonomous in the choice of actions, but not in the choice of ethical concerns and policies it will follow.', 'These are constructed externally, but nonetheless agent-specific and can be private to the agent.', 'The implemented agent follows only one ethical policy at any decision-making moment, because we assumed it can be in only one context at a time.', 'We also assumed that all the contexts are known to the system designer.', 'Our theoretical framework however is more general and does not involve these assumption.', 'The ethical governor of Arkin et al.  [13],', 'and similar solutions to ensure ethical behaviour  [15] “transforms” ethical machine behaviour into a constraint satisfaction problem, namely find a plan that is ethical.', 'A list of precise ethical constraints is compiled, purified of ambiguities and inconsistencies, stopping the autonomous system from performing any activity that violates these constraints.', 'This approach is simple, elegant, but foremost does away with all the complications of ethical reasoning.', 'We consider situations in which no ethical course of action is possible, which is an issue not addressed in  [13,15].', 'Unfortunately, the moment we consider that an unethical action has to occur, the necessity for some form of ethical reasoning creeps in.', 'We focus on establishing a minimal system for ethical decision-making that “transform” ethical machine behaviour into a weak constraint satisfaction problem.', 'The main contribution of our paper is a verifiable ethical decision-making framework that implements a specified ethical decision policy.', 'In our approach we do not develop our own planner or method for generating plans.', 'Rather we assume annotated plans are supplied to the agent.', 'For BDI agents that have access to such a planner we construct a method for selecting among unethical plans, when no ethical plan is available.', 'Our method is verifiable, namely we can prove that if an agent chooses to execute a plan that is in any way unethical, it does so only when it believes that this is the minimally unethical course of action it has available.', 'This way the ethical decision-making is done by the agent and one is able to use agent verification techniques to prove correct behaviour.', 'An alternative approach for engineering ethical behaviour of an agent is to develop a planner that only develops a plan that is ethical, i.e., “push” the ethical decision-making on the side of the planner.', 'There are two immediate problems with this approach that we avoid in ours.', 'First, the possible ethical consequences of a plan cannot be known until the plan is developed.', 'Although the goal of the plan may in itself be ethical, the means to reach it might not.', 'Second, a planner is a tool that can be used by several agents.', 'When the ethical decision-making is on the planner side, all the agents that use the same planner would be subject to the same ethical policy which may or may not be known to the agent.', 'This infringes on the autonomy of the agent to a certain extent.', 'The ethically enhanced agent we described follows only one ethical policy at any decision-making moment, the agent can only be in one context at a time and all the contexts are known (the contexts being the flight phases of the UA).', 'The advantage yielded by this approach is in removing the need for additional calculation within the agent to relate specific plan outcomes to ethical principles via ethical rules.', 'However, it cannot always be the case that the contexts in which an autonomous system operates are predicted or non-overlapping.', 'We would like to extend our implementation to consider the full framework of ethical reasoning as outlined in Section  3.2.', 'Our implemented agent is also limited to only attempting a plan once for any given goal.', 'In a highly dynamic environment, where the predicted ethical outcomes of plans might be rapidly changing, this is clearly unsatisfactory and we would be interested in extending the system so that plans could be re-evaluated if their ethical outcomes had changed, while making sure that the system must, at some point, commit to some plan.', 'There are two ways in which a context can influence the ethical constraining of an agent: (a) by making abstract principles substantive; and (b) by indicating which ethical policy should be used.', 'So far, we use one ethical policy and contexts influence ethical reasoning by specifying what counts as an ethical violation in them.', 'However, it is not difficult to envision situations in which the agent would need to use a different policy.', 'Consider for example, the principles of doing no harm and autonomy (in medicine).', 'During a minor surgery, the patient might prefer a local anaesthetic over a total one, however if the surgery turns out to be more complicated than predicted, the patient’s wishes for local anaesthetic will be disregarded, violating the autonomy principle, in the interest of not harming him/her, preserving the no-harm principle.', 'However, a patient might express the desire to not be resuscitated if his/her heart stops.', 'Under these special circumstances (heart failure), observing the principle of autonomy should be placed as more ethical in the policy than the principle of doing no harm.', 'There are many ways in which a policy can be updated with respect to a special context; we mention two.', 'The most simple way would be to provide a replacement policy.', 'This method is only possible if the context is predetermined, and it also represents significant effort, since all principles have to be re-ordered.', 'Another method is to only alter a part of the policy concerning specific principles.', 'For this method, update procedures need to be developed.', 'One way to develop policy update procedures is to consider them as a special case of belief update and use a belief update operators, see for example  [53] for such operators.', 'Clearly, whether the requirements for belief update operators are fully suited for operators used to update ethical policies is an issue that merits further exploration.', 'A further hindrance to using belief update to update ethical policies could arise from research in belief update being normative, studying which properties a belief update operator should satisfy, rather than operational, i.e., designing belief update operators.', 'Finally, while our examples have been from the UA domain the approach and principles are general enough to be relevant across autonomous systems.', 'Consequently, we aim to extend this work to the formal verification of domestic/healthcare robotics and driver-less cars in the future.']\n",
      "\n",
      "\n",
      "Autonomous systems such as unmanned vehicles are beginning to operate within society. All participants in society are required to follow specific regulations and laws. An autonomous system cannot be an exception. Inevitably an autonomous system will find itself in a situation in which it needs to not only choose to obey a rule or not, but also make a complex ethical decision. However, there exists no obvious way to implement the human understanding of ethical behaviour in computers. Even if we enable autonomous systems to distinguish between more and less ethical alternatives, how can we be sure that they would choose right? We consider autonomous systems with a hybrid architecture in which the highest level of reasoning is executed by a rational (BDI) agent. For such a system, formal verification has been used successfully to prove that specific rules of behaviour are observed when making decisions. We propose a theoretical framework for ethical plan selection that can be formally verified. We implement a rational agent that incorporates a given ethical policy in its plan selection and show that we can formally verify that the agent chooses to execute, to the best of its beliefs, the most ethical available plan.\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0]['body_text'])\n",
    "print('\\n')\n",
    "print(train_dataset[0]['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa680574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(example):\n",
    "    article = ''\n",
    "    for line in example['body_text']:\n",
    "        article += line + ' '\n",
    "    example['prompt'] = article[:1100]                  # limit length to fit model\n",
    "    example['completion'] = example['abstract'][:400]   # limit length to fit model\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a76a9468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a505b935f4b04249b4734fd43ef0012e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32072 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(prepare_data, remove_columns=['title', 'abstract', 'subjareas', 'keywords', 'asjc', 'body_text', 'author_highlights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf076b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'completion'],\n",
      "    num_rows: 32072\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b15cf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous systems are increasingly required in various practical applications, including unmanned aircraft, driver-less cars, healthcare robots, manufacturing robots, etc. In all of these cases it is easy to imagine a situation where an autonomous system causes harm to people or property, as a result of an error in its engineering, or an unfortunate combination of circumstances. Therefore, if such autonomous systems are to operate within society, we must be able to trust that their behaviour complies with the legal, social, and ethical norms of that society. Determining the trustworthiness of technology in this respect is usually delegated to a regulatory body, such as the Federal Aviation Administration (for aircraft in the USA) or the Vehicle Certification Authority (for road vehicles in the UK). The process is known as certification, and is used to determine the safety and reliability of safety-critical technology, including aircraft, road vehicles, nuclear reactors, pharmaceuticals, etc. For non-autonomous systems, such as cars or manned aircraft, it is assumed that the operator\n",
      "Autonomous systems such as unmanned vehicles are beginning to operate within society. All participants in society are required to follow specific regulations and laws. An autonomous system cannot be an exception. Inevitably an autonomous system will find itself in a situation in which it needs to not only choose to obey a rule or not, but also make a complex ethical decision. However, there exists\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0]['prompt'])\n",
    "print(train_dataset[0]['completion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceaf6e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1d3f3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for demonstration only 10 articles selected (should be at least 200 for decent results) \n",
    "finetune_dataset = train_dataset.select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caf4efdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477759cbabc04e888e91978b0ff89d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "15450"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_dataset.to_json(\"finetune_dataset_json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b13af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eafb9ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = \"<OPENAI_KEY>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7e202ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload progress: 100%|████████████████████| 15.4k/15.4k [00:00<00:00, 19.8Mit/s]\n",
      "Uploaded file from finetune_dataset_json: file-RST2GrKiCQ1aWt3iVx3V8eD6\n",
      "Created fine-tune: ft-AWNZQTkindHZgRIUUrO5Wtmr\n",
      "Streaming events until fine-tuning is complete...\n",
      "\n",
      "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
      "[2023-02-13 21:14:55] Created fine-tune: ft-AWNZQTkindHZgRIUUrO5Wtmr\n",
      "\n",
      "Stream interrupted (client disconnected).\n",
      "To resume the stream, run:\n",
      "\n",
      "  openai api fine_tunes.follow -i ft-AWNZQTkindHZgRIUUrO5Wtmr\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.create -t \"finetune_dataset_json\" -m \"davinci\" --suffix \"davin-else\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc204af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-13 21:14:55] Created fine-tune: ft-AWNZQTkindHZgRIUUrO5Wtmr\n",
      "[2023-02-13 21:22:21] Fine-tune costs $0.39\n",
      "[2023-02-13 21:22:26] Fine-tune enqueued. Queue number: 16\n",
      "[2023-02-13 21:23:08] Fine-tune is in the queue. Queue number: 15\n",
      "[2023-02-13 21:23:09] Fine-tune is in the queue. Queue number: 14\n",
      "[2023-02-13 21:23:21] Fine-tune is in the queue. Queue number: 13\n",
      "[2023-02-13 21:26:27] Fine-tune is in the queue. Queue number: 12\n",
      "[2023-02-13 21:27:08] Fine-tune is in the queue. Queue number: 11\n",
      "[2023-02-13 21:29:59] Fine-tune is in the queue. Queue number: 10\n",
      "[2023-02-13 21:30:06] Fine-tune is in the queue. Queue number: 9\n",
      "[2023-02-13 21:32:48] Fine-tune is in the queue. Queue number: 8\n",
      "[2023-02-13 21:37:08] Fine-tune is in the queue. Queue number: 7\n",
      "[2023-02-13 21:38:52] Fine-tune is in the queue. Queue number: 6\n",
      "[2023-02-13 21:39:26] Fine-tune is in the queue. Queue number: 5\n",
      "[2023-02-13 21:40:21] Fine-tune is in the queue. Queue number: 4\n",
      "[2023-02-13 21:41:49] Fine-tune is in the queue. Queue number: 3\n",
      "[2023-02-13 21:41:50] Fine-tune is in the queue. Queue number: 2\n",
      "[2023-02-13 21:42:31] Fine-tune is in the queue. Queue number: 1\n",
      "[2023-02-13 21:43:34] Fine-tune is in the queue. Queue number: 0\n",
      "[2023-02-13 21:44:10] Fine-tune started\n",
      "[2023-02-13 21:45:51] Completed epoch 1/4\n",
      "[2023-02-13 21:45:57] Completed epoch 2/4\n",
      "[2023-02-13 21:46:02] Completed epoch 3/4\n",
      "[2023-02-13 21:46:06] Completed epoch 4/4\n",
      "[2023-02-13 21:46:43] Uploaded model: davinci:ft-personal:davin-else-2023-02-13-20-46-43\n",
      "[2023-02-13 21:46:44] Uploaded result file: file-euEgXzG8VXE5dJouweFquioD\n",
      "[2023-02-13 21:46:44] Fine-tune succeeded\n",
      "\n",
      "Job complete! Status: succeeded 🎉\n",
      "Try out your fine-tuned model:\n",
      "\n",
      "openai api completions.create -m davinci:ft-personal:davin-else-2023-02-13-20-46-43 -p <YOUR_PROMPT>\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.follow -i ft-AWNZQTkindHZgRIUUrO5Wtmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ae59d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now prompt model to summarize article with chunks as described in notebook Summarize_with_chunks_GPT3.ipynb\n",
    "# including:\n",
    "# openai.Completion.create(\n",
    "#     model=FINE_TUNED_MODEL,\n",
    "#     prompt=PROMPT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
